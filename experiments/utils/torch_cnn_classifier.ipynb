{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PYTORCH CNN Classifier\n",
                "\n",
                "To run this notebook on an another benchmark, use\n",
                "\n",
                "```\n",
                "papermill utils/torch_cnn_classifier.ipynb torch_cnn_experiments/[DATASET NAME].ipynb -p DATASET [DATASET NAME]\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# DATASET = 'no_dataset'\n",
                "DATASET = 'human_ensembl_regulatory'\n",
                "# DATASET = 'human_enhancers_ensembl'\n",
                "VERSION = 0\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "human_ensembl_regulatory 0 32 10\n"
                    ]
                }
            ],
            "source": [
                "print(DATASET, VERSION, BATCH_SIZE, EPOCHS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import torch\n",
                "from torch import nn\n",
                "from torch.utils.data import DataLoader\n",
                "from torchtext.data.utils import get_tokenizer\n",
                "from pathlib import Path\n",
                "\n",
                "from genomic_benchmarks.dataset_getters.pytorch_datasets import get_dataset\n",
                "from genomic_benchmarks.models.torch import CNN\n",
                "from genomic_benchmarks.dataset_getters.utils import coll_factory, LetterTokenizer, build_vocab, check_seq_lengths, check_config, VARIABLE_LENGTH_DATASETS\n",
                "from genomic_benchmarks.data_check import is_downloaded, info"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "USE_PADDING = DATASET in VARIABLE_LENGTH_DATASETS\n",
                "    \n",
                "config = {\n",
                "    \"dataset\": DATASET,\n",
                "    \"dataset_version\": VERSION,\n",
                "    \"epochs\": EPOCHS,\n",
                "    \"batch_size\": BATCH_SIZE,\n",
                "    \"use_padding\": USE_PADDING,\n",
                "    \"force_download\": False,\n",
                "    \"run_on_gpu\": True,\n",
                "    \"number_of_classes\": 3,\n",
                "    \"embedding_dim\": 100,\n",
                "}\n",
                "check_config(config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Choose the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\phd\\code\\genomic_benchmarks\\src\\genomic_benchmarks\\utils\\datasets.py:50: UserWarning: No version specified. Using version 0.\n",
                        "  warnings.warn(f\"No version specified. Using version {metadata['version']}.\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset `human_ensembl_regulatory` has 3 classes: enhancer, ocr, promoter.\n",
                        "\n",
                        "The length of genomic intervals ranges from 71 to 802, with average 429.91753643694585 and median 401.0.\n",
                        "\n",
                        "Totally 289061 sequences have been found, 231348 for training and 57713 for testing.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>train</th>\n",
                            "      <th>test</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>enhancer</th>\n",
                            "      <td>85512</td>\n",
                            "      <td>21378</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>ocr</th>\n",
                            "      <td>69902</td>\n",
                            "      <td>17476</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>promoter</th>\n",
                            "      <td>75934</td>\n",
                            "      <td>18859</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          train   test\n",
                            "enhancer  85512  21378\n",
                            "ocr       69902  17476\n",
                            "promoter  75934  18859"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "info(config[\"dataset\"], local_repo=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<genomic_benchmarks.dataset_getters.pytorch_datasets.GenomicClfDataset at 0x19ba1318a90>"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_dset = get_dataset(config[\"dataset\"], 'train', force_download=True, local_repo=True)\n",
                "# train_dset = get_dataset(config[\"dataset\"], 'train', force_download=True, local_repo=True)\n",
                "train_dset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train_dset.all_labels = train_dset.all_labels[85412:85612]\n",
                "# train_dset.all_paths = train_dset.all_paths[85412:85612]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tokenizer and vocab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "vocab len: 9\n",
                        "{'N': 7, '<bos>': 1, '<unk>': 0, 'A': 2, 'T': 3, 'C': 4, '<eos>': 6, 'G': 5, '<pad>': 8}\n"
                    ]
                }
            ],
            "source": [
                "tokenizer = get_tokenizer(LetterTokenizer())\n",
                "\n",
                "vocabulary = build_vocab(train_dset, tokenizer, use_padding=config[\"use_padding\"])\n",
                "\n",
                "print(\"vocab len:\" ,vocabulary.__len__())\n",
                "print(vocabulary.get_stoi())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataloader and batch preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using cpu device\n",
                        "max_seq_len  802\n",
                        "not all sequences are of the same length\n"
                    ]
                }
            ],
            "source": [
                "# Run on GPU or CPU\n",
                "device = 'cuda' if config[\"run_on_gpu\"] and torch.cuda.is_available() else 'cpu'\n",
                "print('Using {} device'.format(device))\n",
                "\n",
                "max_seq_len, nn_input_len = check_seq_lengths(dataset=train_dset, config=config)\n",
                "\n",
                "# Data Loader\n",
                "if(config[\"use_padding\"]):\n",
                "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = nn_input_len)\n",
                "else:\n",
                "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = None)\n",
                "\n",
                "train_loader = DataLoader(train_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "number_of_classes > 2\n"
                    ]
                }
            ],
            "source": [
                "model = CNN(\n",
                "    number_of_classes=config[\"number_of_classes\"],\n",
                "    vocab_size=vocabulary.__len__(),\n",
                "    embedding_dim=config[\"embedding_dim\"],\n",
                "    input_len=nn_input_len\n",
                ").to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\phd\\code\\genomic_benchmarks\\src\\genomic_benchmarks\\dataset_getters\\utils.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  x = torch.tensor(pad(x), dtype=torch.long)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train metrics: \n",
                        " Accuracy: 22.4%, Avg loss: 0.163752 \n",
                        "\n",
                        "Epoch 1\n"
                    ]
                }
            ],
            "source": [
                "model.train(train_loader, epochs=config[\"epochs\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_dset = get_dataset(config[\"dataset\"], 'test')\n",
                "\n",
                "test_loader = DataLoader(test_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)\n",
                "\n",
                "acc, f1 = model.test_multiclass(test_loader)\n",
                "\n",
                "acc, f1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "environment": {
            "name": "pytorch-gpu.1-9.m75",
            "type": "gcloud",
            "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
        },
        "interpreter": {
            "hash": "2b3da2c77dbc8cd5926f59152de74fb64886d0d75c3d06257c3b83d40fdb4d1f"
        },
        "kernelspec": {
            "display_name": "Python 3.8.10 ('genomic_benchmarks')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
