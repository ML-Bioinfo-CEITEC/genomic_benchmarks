{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTORCH CNN Classifier\n",
    "\n",
    "To run this notebook on an another benchmark, use\n",
    "\n",
    "```\n",
    "papermill utils/torch_cnn_classifier.ipynb torch_cnn_experiments/[DATASET NAME].ipynb -p DATASET [DATASET NAME]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DATASET = 'no_dataset'\n",
    "DATASET = 'human_ensembl_regulatory'\n",
    "# DATASET = 'human_enhancers_ensembl'\n",
    "VERSION = 0\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_ensembl_regulatory 0 32 1\n"
     ]
    }
   ],
   "source": [
    "print(DATASET, VERSION, BATCH_SIZE, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "from genomic_benchmarks.dataset_getters.pytorch_datasets import get_dataset\n",
    "from genomic_benchmarks.models.torch import CNN\n",
    "from genomic_benchmarks.dataset_getters.utils import coll_factory, LetterTokenizer, build_vocab, check_seq_lengths, check_config, VARIABLE_LENGTH_DATASETS\n",
    "from genomic_benchmarks.data_check import is_downloaded, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PADDING = DATASET in VARIABLE_LENGTH_DATASETS\n",
    "    \n",
    "config = {\n",
    "    \"dataset\": DATASET,\n",
    "    \"dataset_version\": VERSION,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"use_padding\": USE_PADDING,\n",
    "    \"force_download\": False,\n",
    "    \"run_on_gpu\": True,\n",
    "    \"number_of_classes\": 3,\n",
    "    \"embedding_dim\": 100,\n",
    "}\n",
    "check_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidcechak/genomic_benchmarks/src/genomic_benchmarks/utils/datasets.py:50: UserWarning: No version specified. Using version 0.\n",
      "  warnings.warn(f\"No version specified. Using version {metadata['version']}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset `human_ensembl_regulatory` has 3 classes: enhancer, ocr, promoter.\n",
      "\n",
      "The length of genomic intervals ranges from 71 to 802, with average 429.91753643694585 and median 401.0.\n",
      "\n",
      "Totally 289061 sequences have been found, 231348 for training and 57713 for testing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enhancer</th>\n",
       "      <td>85512</td>\n",
       "      <td>21378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocr</th>\n",
       "      <td>69902</td>\n",
       "      <td>17476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>75934</td>\n",
       "      <td>18859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train   test\n",
       "enhancer  85512  21378\n",
       "ocr       69902  17476\n",
       "promoter  75934  18859"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEQ_PATH = Path.home() / '.genomic_benchmarks' / DATASET\n",
    "# CLASSES = [x.stem for x in (SEQ_PATH/'train').iterdir() if x.is_dir()]\n",
    "# print(CLASSES)\n",
    "\n",
    "# train_dset = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "#     SEQ_PATH / 'train',\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     class_names=CLASSES)\n",
    "\n",
    "# info(config[\"dataset\"])\n",
    "info(config[\"dataset\"], local_repo=True)\n",
    "# info('human_ensembl_regulatory', local_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<genomic_benchmarks.dataset_getters.pytorch_datasets.GenomicClfDataset at 0x7f8d416c4b90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dset = get_dataset(config[\"dataset\"], 'train', force_download=True, local_repo=True)\n",
    "# train_dset = get_dataset(\"/home/davidcechak/genomic_benchmarks/datasets/human_ensembl_regulatory\", 'train', force_download=True)\n",
    "train_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231348"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO remove hack\n",
    "# train_dset.all_paths = train_dset.all_paths[:103]\n",
    "# train_dset.all_labels = train_dset.all_labels[:103] \n",
    "train_dset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len: 9\n",
      "{'<pad>': 8, 'T': 5, '<eos>': 6, 'G': 4, 'A': 3, 'C': 2, '<bos>': 1, 'N': 7, '<unk>': 0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(LetterTokenizer())\n",
    "vocabulary = build_vocab(train_dset, tokenizer, use_padding=config[\"use_padding\"])\n",
    "\n",
    "print(\"vocab len:\" ,vocabulary.__len__())\n",
    "print(vocabulary.get_stoi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader and batch preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "max_seq_len  802\n",
      "not all sequences are of the same length\n"
     ]
    }
   ],
   "source": [
    "# Run on GPU or CPU\n",
    "device = 'cuda' if config[\"run_on_gpu\"] and torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "max_seq_len, nn_input_len = check_seq_lengths(dataset=train_dset, config=config)\n",
    "\n",
    "# Data Loader\n",
    "if(config[\"use_padding\"]):\n",
    "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = nn_input_len)\n",
    "else:\n",
    "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = None)\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_classes > 2\n"
     ]
    }
   ],
   "source": [
    "model = CNN(\n",
    "    number_of_classes=config[\"number_of_classes\"],\n",
    "    vocab_size=vocabulary.__len__(),\n",
    "    embedding_dim=config[\"embedding_dim\"],\n",
    "    input_len=nn_input_len\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidcechak/genomic_benchmarks/src/genomic_benchmarks/dataset_getters/utils.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(pad(x), dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: \n",
      " Accuracy: 1.2%, Avg loss: 0.158763 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader, epochs=config[\"epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.983     0.991       176\n",
      "           1      1.000     0.841     0.914      4024\n",
      "           2      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.847      4200\n",
      "   macro avg      0.667     0.608     0.635      4200\n",
      "weighted avg      1.000     0.847     0.917      4200\n",
      "\n",
      "[0.99140401 0.91390013 0.        ]\n",
      "num_batches  132\n",
      "correct  3559\n",
      "size  4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidcechak/lm/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/davidcechak/lm/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/davidcechak/lm/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7214/17595638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_multiclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# acc = model.test_multiclass(test_loader, class_count=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# acc, f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/genomic_benchmarks/src/genomic_benchmarks/models/torch.py\u001b[0m in \u001b[0;36mtest_multiclass\u001b[0;34m(self, dataloader, class_count, positive_label)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test metrics: \\n Accuracy: {accuracy:>6f}, F1 score: {f1_score:>6f}, Avg loss: {test_loss:>6f} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "test_dset = get_dataset(config[\"dataset\"], 'test')\n",
    "\n",
    "# TODO remove hack\n",
    "# test_dset.all_paths = test_dset.all_paths[:100]\n",
    "# test_dset.all_labels = test_dset.all_labels[:100] \n",
    "test_dset.all_paths = test_dset.all_paths[17300:21500]\n",
    "test_dset.all_labels = test_dset.all_labels[17300:21500] \n",
    "# print(test_dset.__len__())\n",
    "\n",
    "test_loader = DataLoader(test_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)\n",
    "\n",
    "acc, f1 = model.test_multiclass(test_loader, class_count=3)\n",
    "# acc = model.test_multiclass(test_loader, class_count=3)\n",
    "# acc, f1\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "interpreter": {
   "hash": "866798e4020c8c8d4be425aff0057bdeece74f3f2750ee24b5847d9ccc615041"
  },
  "kernelspec": {
   "display_name": "conda-env-bench_env-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
