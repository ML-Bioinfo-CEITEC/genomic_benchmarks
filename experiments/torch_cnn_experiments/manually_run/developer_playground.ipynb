{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoCodingVsIntergenomicSeqs\n",
    "from genomic_benchmarks.dataset_getters.utils import coll_factory, LetterTokenizer, build_vocab, check_seq_lengths, check_config \n",
    "from cnn_model import CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config is correct\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"use_padding\": False,\n",
    "    \"run_on_gpu\": True,\n",
    "    \"dataset\": DemoCodingVsIntergenomicSeqs,\n",
    "    \"number_of_classes\": 2,\n",
    "    \"dataset_version\": 0,\n",
    "    \"force_download\": False,\n",
    "    \"epochs\": 15,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"batch_size\": 32,\n",
    "#   vocabulary that is not present in the training set but is present in the test set\n",
    "    \"vocab_to_add\": [\"N\"],\n",
    "}\n",
    "check_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference /home/jupyter/.genomic_benchmarks/fasta/Homo_sapiens.GRCh38.cdna.all.fa.gz already exists. Skipping.\n",
      "Reference /home/jupyter/.genomic_benchmarks/fasta/Homo_sapiens.GRCh38.dna.toplevel.fa.gz already exists. Skipping.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da648ee11f914925b5ef77894aa72149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2b8be04d234bd6a4dbd55accb1ca58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_dataset_fn = config[\"dataset\"]\n",
    "train_dset = get_dataset_fn('train', force_download=config[\"force_download\"], version=config[\"dataset_version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len: 6\n",
      "{'C': 4, 'A': 3, '<eos>': 5, 'G': 2, 'T': 1, '<bos>': 0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(LetterTokenizer())\n",
    "vocabulary = build_vocab(train_dset, tokenizer, use_padding=config[\"use_padding\"])\n",
    "\n",
    "print(\"vocab len:\" ,vocabulary.__len__())\n",
    "print(vocabulary.get_stoi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader and batch preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "max_seq_len  200\n"
     ]
    }
   ],
   "source": [
    "# Run on GPU or CPU\n",
    "device = 'cuda' if config[\"run_on_gpu\"] and torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "max_seq_len, nn_input_len = check_seq_lengths(dataset=train_dset, config=config)\n",
    "\n",
    "# Data Loader\n",
    "if(config[\"use_padding\"]):\n",
    "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = nn_input_len)\n",
    "else:\n",
    "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = None)\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bench_env/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "model = CNN(\n",
    "    number_of_classes=config[\"number_of_classes\"],\n",
    "    vocab_size=vocabulary.__len__(),\n",
    "    embedding_dim=config[\"embedding_dim\"],\n",
    "    input_len=nn_input_len\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train metrics: \n",
      " Accuracy: 85.5%, Avg loss: 0.569816 \n",
      "\n",
      "Epoch 1\n",
      "Train metrics: \n",
      " Accuracy: 86.3%, Avg loss: 0.566543 \n",
      "\n",
      "Epoch 2\n",
      "Train metrics: \n",
      " Accuracy: 85.8%, Avg loss: 0.563771 \n",
      "\n",
      "Epoch 3\n",
      "Train metrics: \n",
      " Accuracy: 84.6%, Avg loss: 0.571128 \n",
      "\n",
      "Epoch 4\n",
      "Train metrics: \n",
      " Accuracy: 87.1%, Avg loss: 0.564486 \n",
      "\n",
      "Epoch 5\n",
      "Train metrics: \n",
      " Accuracy: 87.8%, Avg loss: 0.559059 \n",
      "\n",
      "Epoch 6\n",
      "Train metrics: \n",
      " Accuracy: 87.6%, Avg loss: 0.558720 \n",
      "\n",
      "Epoch 7\n",
      "Train metrics: \n",
      " Accuracy: 88.4%, Avg loss: 0.557034 \n",
      "\n",
      "Epoch 8\n",
      "Train metrics: \n",
      " Accuracy: 86.6%, Avg loss: 0.559045 \n",
      "\n",
      "Epoch 9\n",
      "Train metrics: \n",
      " Accuracy: 88.3%, Avg loss: 0.555232 \n",
      "\n",
      "Epoch 10\n",
      "Train metrics: \n",
      " Accuracy: 87.3%, Avg loss: 0.557306 \n",
      "\n",
      "Epoch 11\n",
      "Train metrics: \n",
      " Accuracy: 88.7%, Avg loss: 0.559108 \n",
      "\n",
      "Epoch 12\n",
      "Train metrics: \n",
      " Accuracy: 88.1%, Avg loss: 0.555307 \n",
      "\n",
      "Epoch 13\n",
      "Train metrics: \n",
      " Accuracy: 88.2%, Avg loss: 0.555081 \n",
      "\n",
      "Epoch 14\n",
      "Train metrics: \n",
      " Accuracy: 88.3%, Avg loss: 0.553821 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader, epochs=config[\"epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference /home/jupyter/.genomic_benchmarks/fasta/Homo_sapiens.GRCh38.cdna.all.fa.gz already exists. Skipping.\n",
      "Reference /home/jupyter/.genomic_benchmarks/fasta/Homo_sapiens.GRCh38.dna.toplevel.fa.gz already exists. Skipping.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b965a2cd5d6e4d92bff05a3d593e7f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e988b9cf45b46e5a7264833adf4dc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss  435.92515167593956\n",
      "num_batches 782\n",
      "correct 21907\n",
      "size 25000\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.557449 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dset = get_dataset_fn('test', force_download=config[\"force_download\"], version=config[\"dataset_version\"])\n",
    "test_loader = DataLoader(test_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)\n",
    "\n",
    "model.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_evaluation(model, dataloader):\n",
    "    size = dataloader.dataset.__len__()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += model.loss(pred, y).item()\n",
    "            correct += (torch.round(pred) == y).sum().item()\n",
    "\n",
    "    print('test_loss ', test_loss)\n",
    "    print('num_batches', num_batches)\n",
    "    print('correct', correct)\n",
    "    print('size', size)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss  436.8054354786873\n",
      "num_batches 782\n",
      "correct 21834\n",
      "size 25000\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.558575 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "export_evaluation(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "interpreter": {
   "hash": "9828b828580f1cac1b571b33de6cff8bacecc8916095e1bcbc967952ca7105b7"
  },
  "kernelspec": {
   "display_name": "Python [conda env:bench_env]",
   "language": "python",
   "name": "conda-env-bench_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
