{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoMouseEnhancers\n",
    "from genomic_benchmarks.models.torch_cnn import CNN\n",
    "from genomic_benchmarks.dataset_getters.utils import coll_factory, LetterTokenizer, build_vocab, check_seq_lengths, check_config \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config is correct\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"use_padding\": True,\n",
    "    \"run_on_gpu\": True,\n",
    "    \"dataset\": DemoMouseEnhancers,\n",
    "    \"number_of_classes\": 2,\n",
    "    \"dataset_version\": 0,\n",
    "    \"force_download\": False,\n",
    "    \"epochs\": 15,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"batch_size\": 32,\n",
    "#   vocabulary that is not present in the training set but is present in the test set\n",
    "    \"vocab_to_add\": [],\n",
    "}\n",
    "check_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1u3pyaL8smQaJXeOx7YZkjj-Bdpb-jGCM into /home/jupyter/.genomic_benchmarks/translated_demo_mouse_enhancers/demo_mouse_enhancers.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "get_dataset_fn = config[\"dataset\"]\n",
    "train_dset = get_dataset_fn('train', force_download=config[\"force_download\"], version=config[\"dataset_version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len: 8\n",
      "{'N': 5, '<pad>': 7, 'T': 3, 'C': 4, 'A': 2, '<eos>': 6, 'G': 1, '<bos>': 0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(LetterTokenizer())\n",
    "vocabulary = build_vocab(train_dset, tokenizer, use_padding=config[\"use_padding\"])\n",
    "\n",
    "print(\"vocab len:\" ,vocabulary.__len__())\n",
    "print(vocabulary.get_stoi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader and batch preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "max_seq_len  4707\n",
      "not all sequences are of the same length\n"
     ]
    }
   ],
   "source": [
    "# Run on GPU or CPU\n",
    "device = 'cuda' if config[\"run_on_gpu\"] and torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "max_seq_len, nn_input_len = check_seq_lengths(dataset=train_dset, config=config)\n",
    "\n",
    "# Data Loader\n",
    "if(config[\"use_padding\"]):\n",
    "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = nn_input_len)\n",
    "else:\n",
    "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = None)\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(\n",
    "    number_of_classes=config[\"number_of_classes\"],\n",
    "    vocab_size=vocabulary.__len__(),\n",
    "    embedding_dim=config[\"embedding_dim\"],\n",
    "    input_len=nn_input_len\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train metrics: \n",
      " Accuracy: 65.4%, Avg loss: 0.634368 \n",
      "\n",
      "Epoch 1\n",
      "Train metrics: \n",
      " Accuracy: 56.3%, Avg loss: 0.669674 \n",
      "\n",
      "Epoch 2\n",
      "Train metrics: \n",
      " Accuracy: 67.5%, Avg loss: 0.626424 \n",
      "\n",
      "Epoch 3\n",
      "Train metrics: \n",
      " Accuracy: 68.4%, Avg loss: 0.635009 \n",
      "\n",
      "Epoch 4\n",
      "Train metrics: \n",
      " Accuracy: 74.1%, Avg loss: 0.608837 \n",
      "\n",
      "Epoch 5\n",
      "Train metrics: \n",
      " Accuracy: 72.0%, Avg loss: 0.609211 \n",
      "\n",
      "Epoch 6\n",
      "Train metrics: \n",
      " Accuracy: 77.8%, Avg loss: 0.596288 \n",
      "\n",
      "Epoch 7\n",
      "Train metrics: \n",
      " Accuracy: 77.6%, Avg loss: 0.596530 \n",
      "\n",
      "Epoch 8\n",
      "Train metrics: \n",
      " Accuracy: 77.9%, Avg loss: 0.589761 \n",
      "\n",
      "Epoch 9\n",
      "Train metrics: \n",
      " Accuracy: 79.1%, Avg loss: 0.586003 \n",
      "\n",
      "Epoch 10\n",
      "Train metrics: \n",
      " Accuracy: 79.5%, Avg loss: 0.591736 \n",
      "\n",
      "Epoch 11\n",
      "Train metrics: \n",
      " Accuracy: 78.6%, Avg loss: 0.587679 \n",
      "\n",
      "Epoch 12\n",
      "Train metrics: \n",
      " Accuracy: 77.4%, Avg loss: 0.590318 \n",
      "\n",
      "Epoch 13\n",
      "Train metrics: \n",
      " Accuracy: 80.4%, Avg loss: 0.583303 \n",
      "\n",
      "Epoch 14\n",
      "Train metrics: \n",
      " Accuracy: 80.0%, Avg loss: 0.581481 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader, epochs=config[\"epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1u3pyaL8smQaJXeOx7YZkjj-Bdpb-jGCM into /home/jupyter/.genomic_benchmarks/translated_demo_mouse_enhancers/demo_mouse_enhancers.zip... Done.\n",
      "Unzipping...Done.\n",
      "test_loss  4.790966272354126\n",
      "num_batches 8\n",
      "correct 189\n",
      "size 242\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.598871 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dset = get_dataset_fn('test', force_download=config[\"force_download\"], version=config[\"dataset_version\"])\n",
    "test_loader = DataLoader(test_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)\n",
    "\n",
    "model.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "interpreter": {
   "hash": "9828b828580f1cac1b571b33de6cff8bacecc8916095e1bcbc967952ca7105b7"
  },
  "kernelspec": {
   "display_name": "Python [conda env:bench_env]",
   "language": "python",
   "name": "conda-env-bench_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
