{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f8e486",
   "metadata": {
    "papermill": {
     "duration": 0.021819,
     "end_time": "2022-02-16T17:54:18.068062",
     "exception": false,
     "start_time": "2022-02-16T17:54:18.046243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TF CNN Classifier\n",
    "\n",
    "To run this notebook on an another benchmark, use\n",
    "\n",
    "```\n",
    "papermill utils/tf_cnn_classifier.ipynb tf_cnn_experiments/[DATASET NAME].ipynb -p DATASET [DATASET NAME]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbb9431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:54:18.102570Z",
     "iopub.status.busy": "2022-02-16T17:54:18.102279Z",
     "iopub.status.idle": "2022-02-16T17:54:18.104835Z",
     "shell.execute_reply": "2022-02-16T17:54:18.105364Z"
    },
    "papermill": {
     "duration": 0.019265,
     "end_time": "2022-02-16T17:54:18.105617",
     "exception": false,
     "start_time": "2022-02-16T17:54:18.086352",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DATASET = 'demo_coding_vs_intergenomic_seqs'\n",
    "VERSION = 0\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e0324b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:54:18.129711Z",
     "iopub.status.busy": "2022-02-16T17:54:18.129421Z",
     "iopub.status.idle": "2022-02-16T17:54:18.131542Z",
     "shell.execute_reply": "2022-02-16T17:54:18.131304Z"
    },
    "papermill": {
     "duration": 0.013026,
     "end_time": "2022-02-16T17:54:18.131612",
     "exception": false,
     "start_time": "2022-02-16T17:54:18.118586",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "DATASET = \"human_ensembl_regulatory\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982d14ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:54:18.157635Z",
     "iopub.status.busy": "2022-02-16T17:54:18.157361Z",
     "iopub.status.idle": "2022-02-16T17:54:18.159570Z",
     "shell.execute_reply": "2022-02-16T17:54:18.159804Z"
    },
    "papermill": {
     "duration": 0.014668,
     "end_time": "2022-02-16T17:54:18.159892",
     "exception": false,
     "start_time": "2022-02-16T17:54:18.145224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_ensembl_regulatory 0 64 10\n"
     ]
    }
   ],
   "source": [
    "print(DATASET, VERSION, BATCH_SIZE, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06a600",
   "metadata": {
    "papermill": {
     "duration": 0.012084,
     "end_time": "2022-02-16T17:54:18.180331",
     "exception": false,
     "start_time": "2022-02-16T17:54:18.168247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a57e0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:54:18.200357Z",
     "iopub.status.busy": "2022-02-16T17:54:18.197480Z",
     "iopub.status.idle": "2022-02-16T17:54:19.778464Z",
     "shell.execute_reply": "2022-02-16T17:54:19.777633Z"
    },
    "papermill": {
     "duration": 1.590935,
     "end_time": "2022-02-16T17:54:19.778739",
     "exception": false,
     "start_time": "2022-02-16T17:54:18.187804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import numpy as np\n",
    "from genomic_benchmarks.loc2seq import download_dataset\n",
    "from genomic_benchmarks.data_check import is_downloaded, info\n",
    "from genomic_benchmarks.models.tf import vectorize_layer, binary_f1_score\n",
    "from genomic_benchmarks.models.tf import basic_cnn_model_v0 as model\n",
    "\n",
    "if not is_downloaded(DATASET):\n",
    "    download_dataset(DATASET, local_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef313c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:54:19.837828Z",
     "iopub.status.busy": "2022-02-16T17:54:19.837529Z",
     "iopub.status.idle": "2022-02-16T17:54:21.058099Z",
     "shell.execute_reply": "2022-02-16T17:54:21.055448Z"
    },
    "papermill": {
     "duration": 1.238385,
     "end_time": "2022-02-16T17:54:21.058399",
     "exception": true,
     "start_time": "2022-02-16T17:54:19.820014",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset `human_ensembl_regulatory` has 3 classes: enhancer, ocr, promoter.\n",
      "\n",
      "The length of genomic intervals ranges from 71 to 802, with average 429.91753643694585 and median 401.0.\n",
      "\n",
      "Totally 289061 sequences have been found, 231348 for training and 57713 for testing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enhancer</th>\n",
       "      <td>85512</td>\n",
       "      <td>21378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocr</th>\n",
       "      <td>69902</td>\n",
       "      <td>17476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>75934</td>\n",
       "      <td>18859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train   test\n",
       "enhancer  85512  21378\n",
       "ocr       69902  17476\n",
       "promoter  75934  18859"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info(DATASET, local_repo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce24e0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## TF Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "409118c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 231348 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "SEQ_PATH = Path.home() / '.genomic_benchmarks' / DATASET\n",
    "CLASSES = [x.stem for x in (SEQ_PATH/'train').iterdir() if x.is_dir()]\n",
    "\n",
    "train_dset = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    SEQ_PATH / 'train',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_names=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85d1e15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1 0 2 1 1 1 0 1 0 0 0 1 1 0 2 0 2 2 2 2 2 2 1 2 0 0 0 1 2 1 1 1 2 1 0 2 1\n",
      " 0 1 1 2 2 1 2 1 1 2 2 0 2 1 1 2 1 1 1 0 1 0 0 0 2 0 0], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dset))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72b6fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = train_dset.map(lambda x, y: (x, tf.one_hot(y, depth=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91096aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]], shape=(64, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dset))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9706c8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60ac5547",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 't', 'a', 'g', 'c', 'n']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.adapt(train_dset.map(lambda x, y: x))\n",
    "# vectorize_layer.set_vocabulary(vocabulary=np.asarray(['a', 'c', 't', 'g', 'n']))\n",
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a5c8a30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text)-2, label\n",
    "\n",
    "train_ds = train_dset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2216d2dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80f2c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    GlobalAveragePooling1D,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "\n",
    "onehot_layer = tf.keras.layers.Lambda(lambda x: tf.one_hot(tf.cast(x, \"int64\"), 4))\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        onehot_layer,\n",
    "        Conv1D(32, kernel_size=8, data_format=\"channels_last\", activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(16, kernel_size=8, data_format=\"channels_last\", activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(4, kernel_size=8, data_format=\"channels_last\", activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fbf777e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[tf.metrics.CategoricalAccuracy(name='acc'), tfa.metrics.F1Score(num_classes=3, average=\"micro\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57ae2ebd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3615/3615 [==============================] - 170s 47ms/step - loss: 0.6509 - acc: 0.6995 - f1_score: 0.6995\n",
      "Epoch 2/10\n",
      "3615/3615 [==============================] - 170s 47ms/step - loss: 0.5357 - acc: 0.7788 - f1_score: 0.7788\n",
      "Epoch 3/10\n",
      "3615/3615 [==============================] - 170s 47ms/step - loss: 0.5176 - acc: 0.7871 - f1_score: 0.7871\n",
      "Epoch 4/10\n",
      "3615/3615 [==============================] - 175s 48ms/step - loss: 0.5126 - acc: 0.7900 - f1_score: 0.7900\n",
      "Epoch 5/10\n",
      "3615/3615 [==============================] - 174s 48ms/step - loss: 0.5078 - acc: 0.7923 - f1_score: 0.7923\n",
      "Epoch 6/10\n",
      "3615/3615 [==============================] - 176s 49ms/step - loss: 0.5050 - acc: 0.7937 - f1_score: 0.7937\n",
      "Epoch 7/10\n",
      "3615/3615 [==============================] - 175s 48ms/step - loss: 0.5038 - acc: 0.7937 - f1_score: 0.7937\n",
      "Epoch 8/10\n",
      "3615/3615 [==============================] - 176s 49ms/step - loss: 0.5021 - acc: 0.7945 - f1_score: 0.7945\n",
      "Epoch 9/10\n",
      "3615/3615 [==============================] - 175s 48ms/step - loss: 0.4995 - acc: 0.7954 - f1_score: 0.7954\n",
      "Epoch 10/10\n",
      "3615/3615 [==============================] - 175s 48ms/step - loss: 0.4990 - acc: 0.7963 - f1_score: 0.7963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae33fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38e009a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57713 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dset = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    SEQ_PATH / 'test',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_names=CLASSES)\n",
    "\n",
    "test_dset = test_dset.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
    "test_ds =  test_dset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4543bcf7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902/902 [==============================] - 14s 15ms/step - loss: 0.4882 - acc: 0.7956 - f1_score: 0.7956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48824387788772583, 0.7956092953681946, 0.7956093549728394]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b771a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.297511,
   "end_time": "2022-02-16T17:54:24.412334",
   "environment_variables": {},
   "exception": true,
   "input_path": "utils/tf_cnn_classifier.ipynb",
   "output_path": "tf_cnn_experiments/human_ensembl_regulatory.ipynb",
   "parameters": {
    "DATASET": "human_ensembl_regulatory"
   },
   "start_time": "2022-02-16T17:54:17.114823",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
