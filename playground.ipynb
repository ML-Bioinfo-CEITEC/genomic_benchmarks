{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# conda list --export > requirements_conda.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tools.dset_getters import dummy_dset, cvsi_dset\n",
    "\n",
    "dset = dummy_dset()\n",
    "dset.__getitem__(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([6, 9, 1, 4, 8, 7, 4, 7, 6, 6, 6, 0, 6, 4, 9, 6, 3, 7, 3, 2, 3, 4, 4, 1,\n",
       "         9, 1, 2, 4, 3, 4, 3, 1, 5, 8, 1, 1, 7, 9, 1, 3, 8, 3, 4, 5, 8, 0, 9, 2,\n",
       "         6, 5, 6, 5, 3, 7, 5, 9, 7, 9, 7, 7, 6, 0, 2, 9, 8, 0, 7, 2, 6, 1, 7, 9,\n",
       "         5, 1, 2, 1, 6, 9, 1, 8, 6, 1, 2, 3, 1, 0, 5, 9, 9, 0, 7, 8, 8, 5, 7, 2,\n",
       "         3, 5, 0, 2], device='cuda:0'),\n",
       " tensor(0., device='cuda:0', dtype=torch.float64))"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tools.dset_getters import dummy_dset, cvsi_dset\n",
    "\n",
    "dset = cvsi_dset(None)\n",
    "dset.__getitem__(0)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([3, 3, 1, 0, 0, 2, 0, 3, 3, 3, 2, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 2, 1,\n",
       "         2, 2, 0, 0, 1, 0, 1, 3, 0, 1, 1, 3, 1, 2, 1, 1, 3, 2, 3, 2, 1, 2, 2, 3,\n",
       "         3, 0, 0, 0, 3, 3, 1, 1, 2, 0, 3, 1, 3, 1, 0, 2, 1, 2, 1, 2, 3, 0, 1, 0,\n",
       "         3, 1, 0, 2, 1, 0, 0, 3, 3, 0, 0, 1, 2, 2, 2, 0, 3, 2, 0, 3, 1, 2, 1, 1,\n",
       "         1, 0, 2, 0], device='cuda:0'),\n",
       " tensor(0, device='cuda:0'))"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from torchtext.datasets import AG_NEWS, AmazonReviewFull, SogouNews\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from tools.dset_getters import cvsi_dset\n",
    "\n",
    "#TODO uninstall torchtext after check\n",
    "\n",
    "# train_iter = AG_NEWS(split='test')\n",
    "# train_iter = AmazonReviewFull(split='test')\n",
    "train_iter = SogouNews(split='test')\n",
    "\n",
    "dset = to_map_style_dataset(train_iter)\n",
    "\n",
    "\n",
    "print(dset)\n",
    "print(type(dset))\n",
    "\n",
    "print(dset.__getitem__(0))\n",
    "\n",
    "dset = cvsi_dset('train')\n",
    "\n",
    "\n",
    "print(dset)\n",
    "print(type(dset))\n",
    "\n",
    "print(dset.__getitem__(0))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torchtext.data.functional.to_map_style_dataset.<locals>._MapStyleDataset object at 0x7f83002a3ac0>\n",
      "<class 'torchtext.data.functional.to_map_style_dataset.<locals>._MapStyleDataset'>\n",
      "(1, ' ti3 ca1o shi4 jie4 be1i : che2ng fe1i na2 pi2ng he2ng mu4 zi4 yo2u ca1o ji1n pa2i  su4 du4 : ( shuo1 mi2ng : dia3n ji1 zi4 do4ng bo1 fa4ng )\\\\n  shuo1 mi2ng : dia3n ji1 ga1i a4n niu3 , xua3n ze2 yi1 lu4n ta2n ji2 ke3 ')\n",
      "<tools.dset_getters.cvsi_dset object at 0x7f819f431eb0>\n",
      "<class 'tools.dset_getters.cvsi_dset'>\n",
      "('TTCCCCAAGGGAATTACCCCAGGTTGTGTGTTGACCTACGGGGAGACGTAGTGAGTCACGTGAGTCAGTGATGACCAATACTGGACCACCCGCAAGGACCGAGGTGAGACACTCAGTTTCTCGAAACCACATACAAGGATACGACCCATTTTATAGAGTGCGACTTGTATGATAGCTTTGCCAACTTAGGTTTTGGTCAA', 0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tools.basic_model import NeuralNetwork\n",
    "from tools.dset_getters import dummy_dset, cvsi_dset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "dset = cvsi_dset('train')\n",
    "# dset = cvsi_dset('test')\n",
    "\n",
    "\n",
    "\n",
    "dummy = NeuralNetwork(4).cuda()\n",
    "\n",
    "def coll(batch):\n",
    "    mapper = {\n",
    "        'A':0,\n",
    "        'C':1,\n",
    "        'T':2,\n",
    "        'G':3,\n",
    "    }\n",
    "    xs, ys = [],[]\n",
    "    for text,label in batch:\n",
    "        ys.append(torch.tensor(label, dtype=torch.int64))\n",
    "        # xs.append(torch.tensor([mapper[ch] for ch in text]).to('cuda'))\n",
    "        xs.append(torch.tensor([mapper[ch] for ch in text], dtype=torch.float32)) #TODO int doesnt work, why?\n",
    "        \n",
    "\n",
    "    xs = torch.stack(xs)\n",
    "    ys = torch.stack(ys)\n",
    "    return xs.to('cuda'),ys.to('cuda')\n",
    "    \n",
    "\n",
    "loader = DataLoader(dset, batch_size=4, shuffle=False, collate_fn=coll)\n",
    "\n",
    "for el in loader:\n",
    "    # print('loader element')\n",
    "    # print(el)\n",
    "    x,y = el\n",
    "    # print(x.shape)\n",
    "    print(dummy(x))\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NN INPUT\n",
      "torch.float32\n",
      "tensor([[0.1827, 0.2663, 0.2253, 0.2787],\n",
      "        [0.2090, 0.2481, 0.2422, 0.2517],\n",
      "        [0.3230, 0.2289, 0.2608, 0.2566],\n",
      "        [0.2853, 0.2567, 0.2716, 0.2130]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('bench_env': conda)"
  },
  "interpreter": {
   "hash": "9828b828580f1cac1b571b33de6cff8bacecc8916095e1bcbc967952ca7105b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}