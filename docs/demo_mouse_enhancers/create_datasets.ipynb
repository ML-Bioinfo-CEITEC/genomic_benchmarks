{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ovb0gcusfZoB"
   },
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hy19muZc69oS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/katarinagresova/ensembl_scraper.git\n",
      "  Cloning https://github.com/katarinagresova/ensembl_scraper.git to /tmp/pip-req-build-8ibftq7o\n",
      "Requirement already satisfied: bio in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: biopython in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.79)\n",
      "Requirement already satisfied: certifi in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (2.0.6)\n",
      "Requirement already satisfied: idna in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (3.2)\n",
      "Requirement already satisfied: joblib in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.21.2)\n",
      "Requirement already satisfied: pandas in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.3.3)\n",
      "Collecting plac\n",
      "  Downloading plac-1.3.3-py2.py3-none-any.whl (22 kB)\n",
      "Collecting pyfiglet\n",
      "  Downloading pyfiglet-0.8.post1-py2.py3-none-any.whl (865 kB)\n",
      "\u001b[K     |████████████████████████████████| 865 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (2021.3)\n",
      "Requirement already satisfied: PyYAML in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (2.26.0)\n",
      "Requirement already satisfied: scikit-learn in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.0)\n",
      "Requirement already satisfied: scipy in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.7.1)\n",
      "Requirement already satisfied: six in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (4.62.3)\n",
      "Collecting twobitreader\n",
      "  Using cached twobitreader-3.1.7.tar.gz (9.2 kB)\n",
      "Requirement already satisfied: urllib3 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from scraper==0.0.1) (1.26.7)\n",
      "Requirement already satisfied: mygene in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from bio->scraper==0.0.1) (3.2.2)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from mygene->bio->scraper==0.0.1) (0.2.6)\n",
      "Using legacy 'setup.py install' for scraper, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for twobitreader, since package 'wheel' is not installed.\n",
      "Installing collected packages: plac, pyfiglet, twobitreader, scraper\n",
      "    Running setup.py install for twobitreader ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for scraper ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed plac-1.3.3 pyfiglet-0.8.post1 scraper-0.0.1 twobitreader-3.1.7\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/katarinagresova/ensembl_scraper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e3B68s8GkzYn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-12 12:37:40--  https://raw.githubusercontent.com/katarinagresova/ensembl_scraper/main/requirements.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 337 [text/plain]\n",
      "Saving to: ‘requirements.txt’\n",
      "\n",
      "requirements.txt    100%[===================>]     337  --.-KB/s    in 0s      \n",
      "\n",
      "2021-10-12 12:37:40 (11.7 MB/s) - ‘requirements.txt’ saved [337/337]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/katarinagresova/ensembl_scraper/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qI-R7RsBmyDD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bio==1.2 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: biopython==1.79 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.79)\n",
      "Collecting certifi==2021.5.30\n",
      "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Collecting charset-normalizer==2.0.4\n",
      "  Using cached charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: idna==3.2 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (3.2)\n",
      "Collecting joblib==1.0.1\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Requirement already satisfied: numpy==1.21.2 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.21.2)\n",
      "Collecting pandas==1.3.2\n",
      "  Downloading pandas-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: plac==1.3.3 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.3.3)\n",
      "Requirement already satisfied: pyfiglet==0.8.post1 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.8.post1)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (2.8.2)\n",
      "Collecting pytz==2021.1\n",
      "  Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (5.4.1)\n",
      "Requirement already satisfied: requests==2.26.0 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (2.26.0)\n",
      "Collecting scikit-learn==0.24.2\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy==1.7.1 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (1.7.1)\n",
      "Requirement already satisfied: six==1.16.0 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (1.16.0)\n",
      "Collecting threadpoolctl==2.2.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting tqdm==4.62.2\n",
      "  Using cached tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: twobitreader==3.1.7 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (3.1.7)\n",
      "Collecting urllib3==1.26.6\n",
      "  Using cached urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: mygene in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from bio==1.2->-r requirements.txt (line 1)) (3.2.2)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/lib/python3.8/site-packages (from mygene->bio==1.2->-r requirements.txt (line 1)) (0.2.6)\n",
      "Installing collected packages: certifi, charset-normalizer, joblib, pytz, pandas, threadpoolctl, scikit-learn, tqdm, urllib3\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.10.8\n",
      "    Uninstalling certifi-2021.10.8:\n",
      "      Successfully uninstalled certifi-2021.10.8\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.6\n",
      "    Uninstalling charset-normalizer-2.0.6:\n",
      "      Successfully uninstalled charset-normalizer-2.0.6\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2021.3\n",
      "    Uninstalling pytz-2021.3:\n",
      "      Successfully uninstalled pytz-2021.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.3\n",
      "    Uninstalling pandas-1.3.3:\n",
      "      Successfully uninstalled pandas-1.3.3\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.0.0\n",
      "    Uninstalling threadpoolctl-3.0.0:\n",
      "      Successfully uninstalled threadpoolctl-3.0.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0\n",
      "    Uninstalling scikit-learn-1.0:\n",
      "      Successfully uninstalled scikit-learn-1.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.3\n",
      "    Uninstalling tqdm-4.62.3:\n",
      "      Successfully uninstalled tqdm-4.62.3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "Successfully installed certifi-2021.5.30 charset-normalizer-2.0.4 joblib-1.0.1 pandas-1.3.2 pytz-2021.1 scikit-learn-0.24.2 threadpoolctl-2.2.0 tqdm-4.62.2 urllib3-1.26.6\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/petr/.pyenv/versions/3.8.9/envs/genomic_benchmarks/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v22_DrTgYDOh"
   },
   "source": [
    "## Create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2nEuX47IX8Yj"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = {\n",
    "    \"root_dir\": \"../../datasets/\",\n",
    "    \"organisms\": {\n",
    "        \"mus_musculus\": {\n",
    "            \"external_feature\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "user_config = 'user_config.yaml'\n",
    "with open(user_config, 'w') as handle:\n",
    "  yaml.dump(config, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfPKn57BaaaF"
   },
   "source": [
    "## Prepare directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ETRuSt1jaT4C"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_FILE_PATH = Path(\"../../datasets/demo_mouse_enhancers/\")\n",
    "\n",
    "# copied from https://stackoverflow.com/a/57892171\n",
    "def rm_tree(pth: Path):\n",
    "    for child in pth.iterdir():\n",
    "        if child.is_file():\n",
    "            child.unlink()\n",
    "        else:\n",
    "            rm_tree(child)\n",
    "    pth.rmdir()\n",
    "\n",
    "if BASE_FILE_PATH.exists():\n",
    "    rm_tree(BASE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVFl4NtwffLK"
   },
   "source": [
    "## Run tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nsjaflkOSUVS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing organisms:   0%|                               | 0/1 [00:00<?, ?it/s]\n",
      "Processing feature files:   0%|                           | 0/1 [00:00<?, ?it/s]\u001b[AINFO:root:download_file(): Going to download file from path ftp://ftp.ensembl.org/pub/release-100/mysql/regulation_mart_100/mmusculus_external_feature__external_feature__main.txt.gz\n",
      "INFO:root:download_file(): File downloaded to path ../../datasets//tmp//mus_musculus_external_feature.txt.gz.\n",
      "INFO:root:parse_feature_file(): Going to parse file ../../datasets//tmp//mus_musculus_external_feature.txt.gz\n",
      "INFO:root:parse_feature_file(): Done parsing file ../../datasets//tmp//mus_musculus_external_feature.txt.gz\n",
      "\n",
      "\n",
      "Processing feature types:   0%|                           | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[AINFO:root:find_sequences_and_save_to_fasta(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file mm10\n",
      "INFO:root:download_2bit_file(): File for mm10 downloaded to path ../../datasets//tmp/mm10.2bit.\n",
      "INFO:root:find_sequences_and_save_to_fasta(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 619\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 605\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 605\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file mm10\n",
      "INFO:root:download_2bit_file(): File for mm10 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file mm10\n",
      "INFO:root:download_2bit_file(): File for mm10 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types: 100%|██████████████████| 1/1 [10:15<00:00, 615.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "Processing feature files: 100%|██████████████████| 1/1 [10:16<00:00, 616.30s/it]\u001b[A\n",
      "Processing organisms: 100%|██████████████████████| 1/1 [10:16<00:00, 616.30s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m scraper.ensembl_scraper -c user_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../../datasets/mus_musculus_external_feature_enhancer ../../datasets/demo_mouse_enhancers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm requirements.txt user_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../../datasets/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final reformatting\n",
    "\n",
    "  * gzip all CSV files\n",
    "  * add extra formatting to yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../../datasets/demo_mouse_enhancers/ -type f -name \"*.csv\" -exec gzip {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'negative': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna_rm.toplevel.fa.gz'},\n",
       "  'positive': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna_rm.toplevel.fa.gz'}},\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../datasets/demo_mouse_enhancers/metadata.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'negative': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna_rm.toplevel.fa.gz',\n",
       "   'extra_processing': 'ENSEMBL_MOUSE_GENOME'},\n",
       "  'positive': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna_rm.toplevel.fa.gz',\n",
       "   'extra_processing': 'ENSEMBL_MOUSE_GENOME'}},\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['classes']['positive']['extra_processing'] = 'ENSEMBL_MOUSE_GENOME' \n",
    "config['classes']['negative']['extra_processing'] = 'ENSEMBL_MOUSE_GENOME' \n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../datasets/demo_mouse_enhancers/metadata.yaml\", 'w') as handle:\n",
    "  yaml.dump(config, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPVuJo+RW1Iu3Uw8FQ894/8",
   "name": "create_datasets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
