{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/katarinagresova/ensembl_scraper.git@6d3bba8e6be7f5ead58a3bbaed6a4e8cd35e62fd\n",
      "  Cloning https://github.com/katarinagresova/ensembl_scraper.git (to revision 6d3bba8e6be7f5ead58a3bbaed6a4e8cd35e62fd) to /tmp/pip-req-build-fz97hoif\n",
      "  Running command git clone --filter=blob:none -q https://github.com/katarinagresova/ensembl_scraper.git /tmp/pip-req-build-fz97hoif\n",
      "  Running command git rev-parse -q --verify 'sha^6d3bba8e6be7f5ead58a3bbaed6a4e8cd35e62fd'\n",
      "  Running command git fetch -q https://github.com/katarinagresova/ensembl_scraper.git 6d3bba8e6be7f5ead58a3bbaed6a4e8cd35e62fd\n",
      "  Resolved https://github.com/katarinagresova/ensembl_scraper.git to commit 6d3bba8e6be7f5ead58a3bbaed6a4e8cd35e62fd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bio in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.3.3)\n",
      "Requirement already satisfied: biopython in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.79)\n",
      "Requirement already satisfied: certifi in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2.0.11)\n",
      "Requirement already satisfied: idna in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (3.3)\n",
      "Requirement already satisfied: joblib in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.22.2)\n",
      "Requirement already satisfied: pandas in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.4.0)\n",
      "Requirement already satisfied: plac in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.3.4)\n",
      "Requirement already satisfied: pyfiglet in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (0.8.post1)\n",
      "Requirement already satisfied: python-dateutil in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2021.3)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (6.0)\n",
      "Requirement already satisfied: requests in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2.27.1)\n",
      "Requirement already satisfied: scikit-learn in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.0.2)\n",
      "Requirement already satisfied: scipy in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.8.0)\n",
      "Requirement already satisfied: six in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (4.62.3)\n",
      "Requirement already satisfied: twobitreader in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (3.1.7)\n",
      "Requirement already satisfied: urllib3 in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.26.8)\n",
      "Requirement already satisfied: mygene in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from bio->scraper==0.0.1) (3.2.2)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /home/katarina/git/genomic_benchmarks/venv/lib/python3.8/site-packages (from mygene->bio->scraper==0.0.1) (0.2.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/katarina/git/genomic_benchmarks/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/katarinagresova/ensembl_scraper.git@6d3bba8e6be7f5ead58a3bbaed6a4e8cd35e62fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = {\n",
    "    \"root_dir\": \"../../datasets/\",\n",
    "    \"organisms\": {\n",
    "        \"homo_sapiens\": {\n",
    "            \"regulatory_feature\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "user_config = 'user_config.yaml'\n",
    "with open(user_config, 'w') as handle:\n",
    "  yaml.dump(config, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_FILE_PATH = Path(\"../../datasets/human_ensembl_regulatory/\")\n",
    "\n",
    "# copied from https://stackoverflow.com/a/57892171\n",
    "def rm_tree(pth: Path):\n",
    "    for child in pth.iterdir():\n",
    "        if child.is_file():\n",
    "            child.unlink()\n",
    "        else:\n",
    "            rm_tree(child)\n",
    "    pth.rmdir()\n",
    "\n",
    "if BASE_FILE_PATH.exists():\n",
    "    rm_tree(BASE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing organisms:   0%|                               | 0/1 [00:00<?, ?it/s]\n",
      "Processing feature files:   0%|                           | 0/1 [00:00<?, ?it/s]\u001b[AINFO:root:download_file(): Going to download file from path ftp://ftp.ensembl.org/pub/release-100/mysql/regulation_mart_100/hsapiens_regulatory_feature__regulatory_feature__main.txt.gz\n",
      "INFO:root:download_file(): File downloaded to path ../../datasets//tmp//homo_sapiens_regulatory_feature.txt.gz.\n",
      "INFO:root:parse_feature_file(): Going to parse file ../../datasets//tmp//homo_sapiens_regulatory_feature.txt.gz\n",
      "INFO:root:parse_feature_file(): Done parsing file ../../datasets//tmp//homo_sapiens_regulatory_feature.txt.gz\n",
      "\n",
      "\n",
      "Processing feature types:   0%|                           | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 downloaded to path ../../datasets//tmp/hg38.2bit.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 141250\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 141250\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 123915\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 123909\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types:  17%|██▌            | 1/6 [46:10<3:50:52, 2770.60s/it]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 177376\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 177376\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 152129\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 152106\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types:  33%|████▎        | 2/6 [1:17:19<2:29:21, 2240.25s/it]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 132592\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 132592\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 106894\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 106890\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types:  50%|██████▌      | 3/6 [1:37:08<1:28:00, 1760.04s/it]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 97099\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 96572\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 87381\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 87378\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types:  67%|██████████     | 4/6 [1:51:27<46:48, 1404.49s/it]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 35191\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 35191\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 32260\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 32258\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types:  83%|█████████████▎  | 5/6 [1:54:37<16:06, 966.54s/it]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 30436\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 29820\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 25816\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 25816\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types: 100%|███████████████| 6/6 [1:56:39<00:00, 1166.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Processing feature files: 100%|███████████████| 1/1 [1:56:59<00:00, 7019.15s/it]\u001b[A\n",
      "Processing organisms: 100%|███████████████████| 1/1 [1:56:59<00:00, 7019.15s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m scraper.ensembl_scraper -c user_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../../datasets/human_ensembl_regulatory/train\n",
    "!mkdir -p ../../datasets/human_ensembl_regulatory/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../../datasets/homo_sapiens_regulatory_feature_open_chromatin_region/train/positive.csv ../../datasets/human_ensembl_regulatory/train/ocr.csv\n",
    "!mv ../../datasets/homo_sapiens_regulatory_feature_open_chromatin_region/test/positive.csv ../../datasets/human_ensembl_regulatory/test/ocr.csv\n",
    "\n",
    "!mv ../../datasets/homo_sapiens_regulatory_feature_promoter/train/positive.csv ../../datasets/human_ensembl_regulatory/train/promoter.csv\n",
    "!mv ../../datasets/homo_sapiens_regulatory_feature_promoter/test/positive.csv ../../datasets/human_ensembl_regulatory/test/promoter.csv\n",
    "\n",
    "!mv ../../datasets/homo_sapiens_regulatory_feature_enhancer/train/positive.csv ../../datasets/human_ensembl_regulatory/train/enhancer.csv\n",
    "!mv ../../datasets/homo_sapiens_regulatory_feature_enhancer/test/positive.csv ../../datasets/human_ensembl_regulatory/test/enhancer.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_sequnces(file_path, max_len):\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_array = df.values\n",
    "\n",
    "    new_df_array = []\n",
    "    index = 0\n",
    "    for row in df_array:\n",
    "        splits = ((row[3] - row[2]) // max_len) + 1\n",
    "\n",
    "        if splits == 1:\n",
    "            new_df_array.append([index, row[1], row[2], row[3], row[4]])\n",
    "            index += 1\n",
    "\n",
    "        elif splits == 2:\n",
    "            length = (row[3] - row[2]) // 2\n",
    "            new_df_array.append([\n",
    "                index,\n",
    "                row[1],\n",
    "                row[2],\n",
    "                row[2] + length,\n",
    "                row[4]           \n",
    "            ])\n",
    "            index += 1\n",
    "            new_df_array.append([\n",
    "                index,\n",
    "                row[1],\n",
    "                row[2] + length + 1,\n",
    "                row[3],\n",
    "                row[4]           \n",
    "            ])\n",
    "            index += 1\n",
    "        else:\n",
    "            length = (row[3] - row[2]) // splits\n",
    "            new_df_array.append([\n",
    "                index,\n",
    "                row[1],\n",
    "                row[2],\n",
    "                row[2] + length,\n",
    "                row[4]           \n",
    "            ])\n",
    "            index += 1\n",
    "            for i in range(1, splits - 1):\n",
    "                new_df_array.append([\n",
    "                    index,\n",
    "                    row[1],\n",
    "                    row[2] + i*length + 1,\n",
    "                    row[2] + (i + 1)*length,\n",
    "                    row[4]           \n",
    "                ])\n",
    "                index += 1\n",
    "\n",
    "            new_df_array.append([\n",
    "                index,\n",
    "                row[1],\n",
    "                row[2] + (splits - 1)*length + 1,\n",
    "                row[3],\n",
    "                row[4]           \n",
    "            ])\n",
    "            index += 1\n",
    "    new_df = pd.DataFrame(new_df_array, columns=df.columns)\n",
    "    new_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chop_sequnces(\"../../datasets/human_ensembl_regulatory/train/promoter.csv\", 700)\n",
    "chop_sequnces(\"../../datasets/human_ensembl_regulatory/test/promoter.csv\", 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../../datasets/human_ensembl_regulatory/ -type f -name \"*.csv\" -exec gzip {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../../datasets/homo_sapiens_regulatory_feature_enhancer/metadata.yaml ../../datasets/human_ensembl_regulatory/metadata.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'negative': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz'},\n",
       "  'positive': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz'}},\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../datasets/human_ensembl_regulatory/metadata.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'ocr': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz',\n",
       "   'extra_processing': 'ENSEMBL_HUMAN_GENOME'},\n",
       "  'promoter': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz',\n",
       "   'extra_processing': 'ENSEMBL_HUMAN_GENOME'},\n",
       "  'enhancer': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz',\n",
       "   'extra_processing': 'ENSEMBL_HUMAN_GENOME'}},\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config = {\n",
    "    'classes' : {\n",
    "        'ocr': {\n",
    "            'type': config['classes']['positive']['type'],\n",
    "            'url': config['classes']['positive']['url'],\n",
    "            'extra_processing': 'ENSEMBL_HUMAN_GENOME'\n",
    "        },\n",
    "        'promoter': {\n",
    "            'type': config['classes']['positive']['type'],\n",
    "            'url': config['classes']['positive']['url'],\n",
    "            'extra_processing': 'ENSEMBL_HUMAN_GENOME'\n",
    "        },\n",
    "        'enhancer': {\n",
    "            'type': config['classes']['positive']['type'],\n",
    "            'url': config['classes']['positive']['url'],\n",
    "            'extra_processing': 'ENSEMBL_HUMAN_GENOME'\n",
    "        }\n",
    "    },\n",
    "    'version': config['version']\n",
    "}\n",
    "new_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../datasets/human_ensembl_regulatory/metadata.yaml\", 'w') as handle:\n",
    "  yaml.dump(new_config, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm user_config.yaml\n",
    "!rm -rf ../../datasets/tmp/\n",
    "\n",
    "!rm -rf ../../datasets/homo_sapiens_regulatory_feature_CTCF_binding_site\n",
    "!rm -rf ../../datasets/homo_sapiens_regulatory_feature_enhancer\n",
    "!rm -rf ../../datasets/homo_sapiens_regulatory_feature_promoter\n",
    "!rm -rf ../../datasets/homo_sapiens_regulatory_feature_promoter_flanking_region\n",
    "!rm -rf ../../datasets/homo_sapiens_regulatory_feature_TF_binding_site\n",
    "!rm -rf ../../datasets/homo_sapiens_regulatory_feature_open_chromatin_region\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference /home/katarina/.genomic_benchmarks/fasta/Homo_sapiens.GRCh38.dna.toplevel.fa.gz already exists. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:32<00:00,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/katarina/.genomic_benchmarks/human_ensembl_regulatory')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genomic_benchmarks.loc2seq import download_dataset\n",
    "\n",
    "download_dataset(\"human_ensembl_regulatory\", local_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset `human_ensembl_regulatory` has 3 classes: enhancer, ocr, promoter.\n",
      "\n",
      "The length of genomic intervals ranges from 71 to 802, with average 429.91753643694585 and median 401.0.\n",
      "\n",
      "Totally 289061 sequences have been found, 231348 for training and 57713 for testing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enhancer</th>\n",
       "      <td>85512</td>\n",
       "      <td>21378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocr</th>\n",
       "      <td>69902</td>\n",
       "      <td>17476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>75934</td>\n",
       "      <td>18859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train   test\n",
       "enhancer  85512  21378\n",
       "ocr       69902  17476\n",
       "promoter  75934  18859"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genomic_benchmarks.data_check import info\n",
    "\n",
    "info(\"human_ensembl_regulatory\", 0, local_repo=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fb5174addf958ec7b3e9e5d35a565dfd5bab1ae69383cd521f52756e68c7fc3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
