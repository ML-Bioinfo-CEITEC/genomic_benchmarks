{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/katarinagresova/ensembl_scraper.git\n",
      "  Cloning https://github.com/katarinagresova/ensembl_scraper.git to /private/var/folders/q7/pcbd1fnn22l233m3cmvvx1nm0000gn/T/pip-req-build-flj6kfiz\n",
      "  Running command git clone --filter=blob:none -q https://github.com/katarinagresova/ensembl_scraper.git /private/var/folders/q7/pcbd1fnn22l233m3cmvvx1nm0000gn/T/pip-req-build-flj6kfiz\n",
      "  Resolved https://github.com/katarinagresova/ensembl_scraper.git to commit 2c4b3a55383851f9fdaa3ca7470f69b3489a468f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bio in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: biopython in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.79)\n",
      "Requirement already satisfied: certifi in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2.0.4)\n",
      "Requirement already satisfied: idna in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (3.2)\n",
      "Requirement already satisfied: joblib in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.0.1)\n",
      "Requirement already satisfied: numpy in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.21.2)\n",
      "Requirement already satisfied: pandas in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.3.2)\n",
      "Requirement already satisfied: plac in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.3.3)\n",
      "Requirement already satisfied: pyfiglet in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (0.8.post1)\n",
      "Requirement already satisfied: python-dateutil in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2021.1)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (5.4.1)\n",
      "Requirement already satisfied: requests in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (0.24.2)\n",
      "Requirement already satisfied: scipy in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.7.1)\n",
      "Requirement already satisfied: six in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (4.62.2)\n",
      "Requirement already satisfied: twobitreader in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (3.1.7)\n",
      "Requirement already satisfied: urllib3 in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from scraper==0.0.1) (1.26.6)\n",
      "Requirement already satisfied: mygene in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from bio->scraper==0.0.1) (3.2.2)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /Users/katarina/Documents/repositories/GitHub/genomic_benchmarks/venv/lib/python3.8/site-packages (from mygene->bio->scraper==0.0.1) (0.2.6)\n",
      "Using legacy 'setup.py install' for scraper, since package 'wheel' is not installed.\n",
      "Installing collected packages: scraper\n",
      "  Attempting uninstall: scraper\n",
      "    Found existing installation: scraper 0.0.1\n",
      "    Uninstalling scraper-0.0.1:\n",
      "      Successfully uninstalled scraper-0.0.1\n",
      "    Running setup.py install for scraper ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed scraper-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/katarinagresova/ensembl_scraper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = {\n",
    "    \"root_dir\": \"../../datasets/\",\n",
    "    \"organisms\": {\n",
    "        \"homo_sapiens\": {\n",
    "            \"external_feature\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "user_config = 'user_config.yaml'\n",
    "with open(user_config, 'w') as handle:\n",
    "  yaml.dump(config, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_FILE_PATH = Path(\"../../datasets/human_tss_ensembl/\")\n",
    "\n",
    "# copied from https://stackoverflow.com/a/57892171\n",
    "def rm_tree(pth: Path):\n",
    "    for child in pth.iterdir():\n",
    "        if child.is_file():\n",
    "            child.unlink()\n",
    "        else:\n",
    "            rm_tree(child)\n",
    "    pth.rmdir()\n",
    "\n",
    "if BASE_FILE_PATH.exists():\n",
    "    rm_tree(BASE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing organisms:   0%|                               | 0/1 [00:00<?, ?it/s]\n",
      "Processing feature files:   0%|                           | 0/1 [00:00<?, ?it/s]\u001b[AINFO:root:download_file(): Going to download file from path ftp://ftp.ensembl.org/pub/release-100/mysql/regulation_mart_100/hsapiens_external_feature__external_feature__main.txt.gz\n",
      "INFO:root:download_file(): File ../../datasets//tmp//homo_sapiens_external_feature.txt.gz already exists. Not going to download.\n",
      "INFO:root:parse_feature_file(): Going to parse file ../../datasets//tmp//homo_sapiens_external_feature.txt.gz\n",
      "INFO:root:parse_feature_file(): Done parsing file ../../datasets//tmp//homo_sapiens_external_feature.txt.gz\n",
      "\n",
      "\n",
      "Processing feature types:   0%|                           | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 82370\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 82370\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 77421\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 77421\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types:  50%|█████████         | 1/2 [11:00<11:00, 660.83s/it]\u001b[A\u001b[AINFO:root:find_sequences(): Going to find sequences based on genomic loci.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:find_sequences(): Done finding sequences.\n",
      "INFO:root:remove_low_quality(): Going to preprocess sequences.\n",
      "INFO:root:remove_low_quality(): Original number of sequences: 388825\n",
      "INFO:root:remove_low_quality(): Number of sequences after contigs rejection: 388825\n",
      "INFO:root:remove_low_quality(): Number of sequences after outlier rejection: 332646\n",
      "INFO:root:remove_low_quality(): Number of sequences after Ns rejection: 332495\n",
      "INFO:root:remove_low_quality(): Done preprocessing sequences.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "INFO:root:download_2bit_file(): Going to download 2bit file hg38\n",
      "INFO:root:download_2bit_file(): File for hg38 already exists. Not going to download.\n",
      "\n",
      "\n",
      "Processing feature types: 100%|███████████████| 2/2 [4:20:20<00:00, 7810.49s/it]\n",
      "\n",
      "Processing feature files: 100%|██████████████| 1/1 [4:20:22<00:00, 15622.41s/it]\n",
      "Processing organisms: 100%|██████████████████| 1/1 [4:20:22<00:00, 15622.41s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m scraper.ensembl_scraper -c user_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../../datasets/homo_sapiens_external_feature_transcription_start_site ../../datasets/human_tss_ensembl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: requirements.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm requirements.txt user_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../../datasets/tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../../datasets/homo_sapiens_external_feature_enhancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final reformating\n",
    "\n",
    "  * gzip all CSV files\n",
    "  * add extra formatting to yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../../datasets/human_tss_ensembl/ -type f -name \"*.csv\" -exec gzip {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'negative': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz'},\n",
       "  'positive': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz'}},\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../datasets/human_tss_ensembl/metadata.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'negative': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz',\n",
       "   'extra_processing': 'ENSEMBL_HUMAN_GENOME'},\n",
       "  'positive': {'type': 'fa.gz',\n",
       "   'url': 'ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz',\n",
       "   'extra_processing': 'ENSEMBL_HUMAN_GENOME'}},\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['classes']['positive']['extra_processing'] = 'ENSEMBL_HUMAN_GENOME' \n",
    "config['classes']['negative']['extra_processing'] = 'ENSEMBL_HUMAN_GENOME' \n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../datasets/human_tss_ensembl/metadata.yaml\", 'w') as handle:\n",
    "  yaml.dump(config, handle)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6aefa309fdc551cffdb69c1b229c63cc8afbc3d2cc6c7acf643414f933d1f738"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
